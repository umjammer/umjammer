# ディープラーニングで校正

と言っても Web の API 使うんだけどね。
Recruit の [a3rt](https://a3rt.recruit-tech.co.jp/product/proofreadingAPI/) の Proofreading API です。

## いままで

 1. キャプチャ
 2. Google Docs OCR ほんの基本的な校正も行える (赤の波線がつく)
     * ドキュメントからプレーンテキストを取り出す[スクリプト](https://gist.github.com/umjammer/30b1977bfaa0c36241261016052669ae#file-docxview-sh)
 3. 手動校正
     * "「"がダメだったような気が
     * カタカナの"ニ"と数字の"二"とか
     * "パ"と"バ"とか
 4. Web サービス [たぶんこれ](http://enno.jp/)使ったはず（覚えていないw）
     * "洒落"を見つけてくれた (酒になってた)
 5. 何回も間を空けて読み返す
     * たまに見つかる
 5. a3rt を試してみたがダメだった...
     * https://twitter.com/umjammer/status/972039212236095490

(3.) と (5.) がやっぱり大変なんだよね。
(3.) は気が狂いそうだし、 (5.) は何回読んでも出てくるし...
(2.) は当時 Google のくせに全然ダメだった。今はどうなんだろう？
(4.) は機械学習系じゃないのが多いからやっぱり限界があるし。
 
## 使えるようになった？ 2019-05-15

久しぶりに起動してみたら指摘してくれた。 Twitter で呟いたから学習させた？
それとも一年以上の学習の結果なのか？

サジェスチョンは適当だがそこは別に手動でいいのだ。修正箇所は少ないんだからそこは人力で OK。
広大な文字の海から変なのを見つける作業が大変なのであって、そこを AI に任せたいのだ。
